{"cells":[{"cell_type":"markdown","metadata":{"graffitiCellId":"id_6801mjh","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"251399EF3DD149548D760A5F24266338","mdEditEnable":false},"source":"# 语言模型\n## n元语法\n- 定义\n$$\nP(w_1, w_2, \\ldots, w_T) = \\prod_{t=1}^T P(w_t \\mid w_{t-(n-1)}, \\ldots, w_{t-1}) .\n$$\n- 缺点\n1、 参数空间过大\n2、数据稀疏\n\n## 时序数据的采样\n### 随机采样\n每次从数据里随机采样一个小批量。其中批量大小`batch_size`是每个小批量的样本数，`num_steps`是每个样本所包含的时间步数。\n在随机采样中，每个样本是原始序列上任意截取的一段序列，相邻的两个随机小批量在原始序列上的位置不一定相毗邻。\n### 相邻采样\n在相邻采样中，相邻的两个随机小批量在原始序列上的位置相毗邻。"},{"cell_type":"code","execution_count":1,"metadata":{"graffitiCellId":"id_210oytz","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"434D33D454FB42C38C6F9816E9E1FBF4","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"chars: 想要有直升机 想要和你飞到宇宙去 想要和\nindices: [757, 451, 284, 893, 55, 102, 924, 757, 451, 890, 360, 889, 209, 702, 949, 37, 924, 757, 451, 890]\nX:  tensor([[18, 19, 20, 21, 22, 23],\n        [ 0,  1,  2,  3,  4,  5]]) \nY: tensor([[19, 20, 21, 22, 23, 24],\n        [ 1,  2,  3,  4,  5,  6]]) \n\nX:  tensor([[ 6,  7,  8,  9, 10, 11],\n        [12, 13, 14, 15, 16, 17]]) \nY: tensor([[ 7,  8,  9, 10, 11, 12],\n        [13, 14, 15, 16, 17, 18]]) \n\nX:  tensor([[ 0,  1,  2,  3,  4,  5],\n        [15, 16, 17, 18, 19, 20]]) \nY: tensor([[ 1,  2,  3,  4,  5,  6],\n        [16, 17, 18, 19, 20, 21]]) \n\nX:  tensor([[ 6,  7,  8,  9, 10, 11],\n        [21, 22, 23, 24, 25, 26]]) \nY: tensor([[ 7,  8,  9, 10, 11, 12],\n        [22, 23, 24, 25, 26, 27]]) \n\n","name":"stdout"}],"source":"#读取数据集\nwith open('/home/kesci/input/jaychou_lyrics4703/jaychou_lyrics.txt') as f:\n    corpus_chars = f.read()\n\ncorpus_chars = corpus_chars.replace('\\n', ' ').replace('\\r', ' ')\ncorpus_chars = corpus_chars[: 10000]\n\n#建立字符索引\nidx_to_char = list(set(corpus_chars)) # 去重，得到索引到字符的映射\nchar_to_idx = {char: i for i, char in enumerate(idx_to_char)} # 字符到索引的映射\nvocab_size = len(char_to_idx)\n\ncorpus_indices = [char_to_idx[char] for char in corpus_chars]  # 将每个字符转化为索引，得到一个索引的序列\nsample = corpus_indices[: 20]\nprint('chars:', ''.join([idx_to_char[idx] for idx in sample]))\nprint('indices:', sample)\n\ndef load_data_jay_lyrics():\n    with open('/home/kesci/input/jaychou_lyrics4703/jaychou_lyrics.txt') as f:\n        corpus_chars = f.read()\n    corpus_chars = corpus_chars.replace('\\n', ' ').replace('\\r', ' ')\n    corpus_chars = corpus_chars[0:10000]\n    idx_to_char = list(set(corpus_chars))\n    char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n    vocab_size = len(char_to_idx)\n    corpus_indices = [char_to_idx[char] for char in corpus_chars]\n    return corpus_indices, char_to_idx, idx_to_char, vocab_size\n    \n#随机采样\nimport torch\nimport random\ndef data_iter_random(corpus_indices, batch_size, num_steps, device=None):\n    # 减1是因为对于长度为n的序列，X最多只有包含其中的前n - 1个字符\n    num_examples = (len(corpus_indices) - 1) // num_steps  # 下取整，得到不重叠情况下的样本个数\n    example_indices = [i * num_steps for i in range(num_examples)]  # 每个样本的第一个字符在corpus_indices中的下标\n    random.shuffle(example_indices)\n\n    def _data(i):\n        # 返回从i开始的长为num_steps的序列\n        return corpus_indices[i: i + num_steps]\n    if device is None:\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n    for i in range(0, num_examples, batch_size):\n        # 每次选出batch_size个随机样本\n        batch_indices = example_indices[i: i + batch_size]  # 当前batch的各个样本的首字符的下标\n        X = [_data(j) for j in batch_indices]\n        Y = [_data(j + 1) for j in batch_indices]\n        yield torch.tensor(X, device=device), torch.tensor(Y, device=device)\n        \n#相邻采样\ndef data_iter_consecutive(corpus_indices, batch_size, num_steps, device=None):\n    if device is None:\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    corpus_len = len(corpus_indices) // batch_size * batch_size  # 保留下来的序列的长度\n    corpus_indices = corpus_indices[: corpus_len]  # 仅保留前corpus_len个字符\n    indices = torch.tensor(corpus_indices, device=device)\n    indices = indices.view(batch_size, -1)  # resize成(batch_size, )\n    batch_num = (indices.shape[1] - 1) // num_steps\n    for i in range(batch_num):\n        i = i * num_steps\n        X = indices[:, i: i + num_steps]\n        Y = indices[:, i + 1: i + num_steps + 1]\n        yield X, Y\n\n#采样输出\nmy_seq = list(range(30))\nfor X, Y in data_iter_random(my_seq, batch_size=2, num_steps=6):\n    print('X: ', X, '\\nY:', Y, '\\n')\nfor X, Y in data_iter_consecutive(my_seq, batch_size=2, num_steps=6):\n    print('X: ', X, '\\nY:', Y, '\\n')"},{"metadata":{"id":"BA5F848475E143A3BAE1DC5EE2755119","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"}},"cell_type":"code","outputs":[],"source":"","execution_count":null}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}