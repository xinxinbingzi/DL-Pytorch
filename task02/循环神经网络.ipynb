{"cells":[{"attachments":{"%E5%9B%BE%E7%89%87.png":{"image/png":"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"}},"cell_type":"markdown","metadata":{"graffitiCellId":"id_m8ksq1l","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"ECBDC362D7D147C888F06244BC276561","mdEditEnable":false},"source":"# 循环神经网络\n循环神经网络引入一个隐藏变量$H$，用$H_{t}$表示$H$在时间步$t$的值。$H_{t}$的计算基于$X_{t}$和$H_{t-1}$，可以认为$H_{t}$记录了到当前字符为止的序列信息，利用$H_{t}$对序列的下一个字符进行预测。\n![Image Name](https://cdn.kesci.com/upload/image/q5jkm0v44i.png?imageView2/0/w/640/h/640)\n## 循环神经网络的构造\n\n我们先看循环神经网络的具体构造。假设$\\boldsymbol{X}_t \\in \\mathbb{R}^{n \\times d}$是时间步$t$的小批量输入，$\\boldsymbol{H}_t  \\in \\mathbb{R}^{n \\times h}$是该时间步的隐藏变量，则：\n\n\n$$\n\\boldsymbol{H}_t = \\phi(\\boldsymbol{X}_t \\boldsymbol{W}_{xh} + \\boldsymbol{H}_{t-1} \\boldsymbol{W}_{hh}  + \\boldsymbol{b}_h).\n$$\n\n\n其中，$\\boldsymbol{W}_{xh} \\in \\mathbb{R}^{d \\times h}$，$\\boldsymbol{W}_{hh} \\in \\mathbb{R}^{h \\times h}$，$\\boldsymbol{b}_{h} \\in \\mathbb{R}^{1 \\times h}$，$\\phi$函数是非线性激活函数。由于引入了$\\boldsymbol{H}_{t-1} \\boldsymbol{W}_{hh}$，$H_{t}$能够捕捉截至当前时间步的序列的历史信息，就像是神经网络当前时间步的状态或记忆一样。由于$H_{t}$的计算基于$H_{t-1}$，上式的计算是循环的，使用循环计算的网络即循环神经网络（recurrent neural network）。\n\n在时间步$t$，输出层的输出为：\n\n\n$$\n\\boldsymbol{O}_t = \\boldsymbol{H}_t \\boldsymbol{W}_{hq} + \\boldsymbol{b}_q.\n$$\n\n其中$\\boldsymbol{W}_{hq} \\in \\mathbb{R}^{h \\times q}$，$\\boldsymbol{b}_q \\in \\mathbb{R}^{1 \\times q}$。\n\n### one-hot向量\n假设词典大小是$N$，每次字符对应一个从$0$到$N-1$的唯一的索引，则该字符的向量是一个长度为$N$的向量，若字符的索引是$i$，则该向量的第$i$个位置为$1$，其他位置为$0$。下面分别展示了索引为0和2的one-hot向量，向量长度等于词典大小。\n\n### 裁剪梯度\n\n循环神经网络中较容易出现梯度衰减或梯度爆炸，这会导致网络几乎无法训练。裁剪梯度（clip gradient）是一种应对梯度爆炸的方法。假设我们把所有模型参数的梯度拼接成一个向量 $\\boldsymbol{g}$，并设裁剪的阈值是$\\theta$。裁剪后的梯度\n$$\n \\min\\left(\\frac{\\theta}{\\|\\boldsymbol{g}\\|}, 1\\right)\\boldsymbol{g}\n$$\n的$L_2$范数不超过$\\theta$。\n### 困惑度\n* 最佳情况下，模型总是把标签类别的概率预测为1，此时困惑度为1；\n* 最坏情况下，模型总是把标签类别的概率预测为0，此时困惑度为正无穷；\n* 基线情况下，模型总是预测所有类别的概率都相同，此时困惑度为类别个数。\n\n显然，任何一个有效模型的困惑度必须小于类别个数。在本例中，困惑度必须小于词典大小`vocab_size`。\n\n### 定义模型训练函数\n1. 使用困惑度评价模型。\n2. 在迭代模型参数前裁剪梯度。\n3. 对时序数据采用不同采样方法将导致隐藏状态初始化的不同。"},{"cell_type":"code","execution_count":2,"metadata":{"graffitiCellId":"id_uso50ly","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"20171E08BC064A1DA6315C234E0EDF33","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"epoch 50, perplexity 66.905005, time 0.66 sec\n - 分开 我不要这生 我不 我想你的爱你 我不要你想你 我不要这 你使我 别怪我 我不就 一九两颗三颗四步 \n - 不分开 快颗我 别你我 三颗我 别你的颗我 我不能再想你 我知 这你再 你什么 一颗四颗三颗四步望步四颗我\nepoch 100, perplexity 9.921061, time 0.61 sec\n - 分开 一颗两剧 在一定空 在一定空 你在不空 你一定空 你在不空 你不了空 不么不空 你不定空 你我不定\n - 不分开吗 我不要再想 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 我不 \nepoch 150, perplexity 2.876940, time 0.61 sec\n - 分开 有蟑去用教 有话就没有喝水也能活 脑袋瓜有一点秀逗 猎物死了它比谁都难过 印地安的字迹依然清晰 深\n - 不分开扫 我不能再想 我不 再不 我不能再想 我不 我不 我不要再想你 不知不觉 你已经离开我 不知不觉 \nepoch 200, perplexity 1.611338, time 0.61 sec\n - 分开 不愿去对三 用只拽  全要怕空屋前的河牵就 无地的老斑鸠  一成了里 我跟悔努力  没有你在我有多\n - 不分开期 我后能 你你我的太头就怎么卷下 看能开化来香下不及 说我一定熟力 周杰会不多 除非温没 全家怕日\nepoch 250, perplexity 1.307554, time 0.61 sec\n - 分开 沙什么不霜落 哼哼哈兮 是谁用 太诉我的见画一只 家地就红开永 快使用双截棍 哼哼哈兮 快使用双截\n - 不分开扫 我叫你爸说你的家桌就像 我可你 开子我 我有大声宣布 你怀手 安里的你像语言暴力 我已无能为力再\n","name":"stdout"}],"source":"import torch\nimport torch.nn as nn\nimport time\nimport math\nimport sys\nsys.path.append(\"/home/kesci/input\")\nimport d2l_jay9460 as d2l\n(corpus_indices, char_to_idx, idx_to_char, vocab_size) = d2l.load_data_jay_lyrics()\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n#实现one-hot\ndef one_hot(x, n_class, dtype=torch.float32):\n    result = torch.zeros(x.shape[0], n_class, dtype=dtype, device=x.device)  # shape: (n, n_class)\n    result.scatter_(1, x.long().view(-1, 1), 1)  # result[i, x[i, 0]] = 1\n    return result\n\ndef to_onehot(X, n_class):\n    return [one_hot(X[:, i], n_class) for i in range(X.shape[1])]\n    \n#初始化模型参数\nnum_inputs, num_hiddens, num_outputs = vocab_size, 256, vocab_size\n\ndef get_params():\n    def _one(shape):\n        param = torch.zeros(shape, device=device, dtype=torch.float32)\n        nn.init.normal_(param, 0, 0.01)\n        return torch.nn.Parameter(param)\n\n    # 隐藏层参数\n    W_xh = _one((num_inputs, num_hiddens))\n    W_hh = _one((num_hiddens, num_hiddens))\n    b_h = torch.nn.Parameter(torch.zeros(num_hiddens, device=device))\n    # 输出层参数\n    W_hq = _one((num_hiddens, num_outputs))\n    b_q = torch.nn.Parameter(torch.zeros(num_outputs, device=device))\n    return (W_xh, W_hh, b_h, W_hq, b_q)\n    \n#定义模型\ndef rnn(inputs, state, params):\n    # inputs和outputs皆为num_steps个形状为(batch_size, vocab_size)的矩阵\n    W_xh, W_hh, b_h, W_hq, b_q = params\n    H, = state\n    outputs = []\n    for X in inputs:\n        H = torch.tanh(torch.matmul(X, W_xh) + torch.matmul(H, W_hh) + b_h)\n        Y = torch.matmul(H, W_hq) + b_q\n        outputs.append(Y)\n    return outputs, (H,)\n    \ndef init_rnn_state(batch_size, num_hiddens, device):\n    return (torch.zeros((batch_size, num_hiddens), device=device), )\n\n#裁剪梯度   \ndef grad_clipping(params, theta, device):\n    norm = torch.tensor([0.0], device=device)\n    for param in params:\n        norm += (param.grad.data ** 2).sum()\n    norm = norm.sqrt().item()\n    if norm > theta:\n        for param in params:\n            param.grad.data *= (theta / norm)\n            \n#定义预测函数\ndef predict_rnn(prefix, num_chars, rnn, params, init_rnn_state,\n                num_hiddens, vocab_size, device, idx_to_char, char_to_idx):\n    state = init_rnn_state(1, num_hiddens, device)\n    output = [char_to_idx[prefix[0]]]   # output记录prefix加上预测的num_chars个字符\n    for t in range(num_chars + len(prefix) - 1):\n        # 将上一时间步的输出作为当前时间步的输入\n        X = to_onehot(torch.tensor([[output[-1]]], device=device), vocab_size)\n        # 计算输出和更新隐藏状态\n        (Y, state) = rnn(X, state, params)\n        # 下一个时间步的输入是prefix里的字符或者当前的最佳预测字符\n        if t < len(prefix) - 1:\n            output.append(char_to_idx[prefix[t + 1]])\n        else:\n            output.append(Y[0].argmax(dim=1).item())\n    return ''.join([idx_to_char[i] for i in output])\n\ndef train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,\n                          vocab_size, device, corpus_indices, idx_to_char,\n                          char_to_idx, is_random_iter, num_epochs, num_steps,\n                          lr, clipping_theta, batch_size, pred_period,\n                          pred_len, prefixes):\n    if is_random_iter:\n        data_iter_fn = d2l.data_iter_random\n    else:\n        data_iter_fn = d2l.data_iter_consecutive\n    params = get_params()\n    loss = nn.CrossEntropyLoss()\n\n    for epoch in range(num_epochs):\n        if not is_random_iter:  # 如使用相邻采样，在epoch开始时初始化隐藏状态\n            state = init_rnn_state(batch_size, num_hiddens, device)\n        l_sum, n, start = 0.0, 0, time.time()\n        data_iter = data_iter_fn(corpus_indices, batch_size, num_steps, device)\n        for X, Y in data_iter:\n            if is_random_iter:  # 如使用随机采样，在每个小批量更新前初始化隐藏状态\n                state = init_rnn_state(batch_size, num_hiddens, device)\n            else:  # 否则需要使用detach函数从计算图分离隐藏状态\n                for s in state:\n                    s.detach_()\n            # inputs是num_steps个形状为(batch_size, vocab_size)的矩阵\n            inputs = to_onehot(X, vocab_size)\n            # outputs有num_steps个形状为(batch_size, vocab_size)的矩阵\n            (outputs, state) = rnn(inputs, state, params)\n            # 拼接之后形状为(num_steps * batch_size, vocab_size)\n            outputs = torch.cat(outputs, dim=0)\n            # Y的形状是(batch_size, num_steps)，转置后再变成形状为\n            # (num_steps * batch_size,)的向量，这样跟输出的行一一对应\n            y = torch.flatten(Y.T)\n            # 使用交叉熵损失计算平均分类误差\n            l = loss(outputs, y.long())\n            \n            # 梯度清0\n            if params[0].grad is not None:\n                for param in params:\n                    param.grad.data.zero_()\n            l.backward()\n            grad_clipping(params, clipping_theta, device)  # 裁剪梯度\n            d2l.sgd(params, lr, 1)  # 因为误差已经取过均值，梯度不用再做平均\n            l_sum += l.item() * y.shape[0]\n            n += y.shape[0]\n\n        if (epoch + 1) % pred_period == 0:\n            print('epoch %d, perplexity %f, time %.2f sec' % (\n                epoch + 1, math.exp(l_sum / n), time.time() - start))\n            for prefix in prefixes:\n                print(' -', predict_rnn(prefix, pred_len, rnn, params, init_rnn_state,\n                    num_hiddens, vocab_size, device, idx_to_char, char_to_idx))\n                    \nnum_epochs, num_steps, batch_size, lr, clipping_theta = 250, 35, 32, 1e2, 1e-2\npred_period, pred_len, prefixes = 50, 50, ['分开', '不分开']                    \n\n#采用随机采样训练模型并创作歌词\ntrain_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,\n                      vocab_size, device, corpus_indices, idx_to_char,\n                      char_to_idx, True, num_epochs, num_steps, lr,\n                      clipping_theta, batch_size, pred_period, pred_len,\n                      prefixes)       \n#采用相邻采样训练模型并创作歌词                      \ntrain_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,\n                      vocab_size, device, corpus_indices, idx_to_char,\n                      char_to_idx, False, num_epochs, num_steps, lr,\n                      clipping_theta, batch_size, pred_period, pred_len,\n                      prefixes)                      "},{"cell_type":"code","execution_count":4,"metadata":{"graffitiCellId":"id_j3cpkcl","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"0299EF9E9126417B80153A137538E01E","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"epoch 50, perplexity 10.271949, time 0.41 sec\n - 分开 我想你你在我面多 一枝杨柳 你在一场  满天的让我面红的可爱女人 坏坏的让我疯狂的可爱女人 坏坏的\n - 不分开 我想你你不你 我 你这样牵着你的手爱女人 坏坏的让我疯狂的可爱女人 坏坏的让我疯狂的可爱女人 坏坏\nepoch 100, perplexity 1.295111, time 0.42 sec\n - 分开 我不了口让 在不知篮觉 你已经很久  不知不觉 我跟了这节奏 后知后觉 又过了一个秋 后知后觉 我\n - 不分开 你说啊爸你怎么打我妈妈这样不了口简 我  有念再考倒我 说散 你想很久了吧? 败给你的黑色幽默 说\nepoch 150, perplexity 1.068281, time 0.47 sec\n - 分开 我不起跳你的我  这样的那年 我爱你的让美演出的可不戏 宁愿心碎哭泣 再狠狠忘记 你爱过我的证据 \n - 不分开 你说啊爸你怎么打我手 一说走 如果我的见你是一场悲剧 我可以让我满腔的怒火 我想揍你已经很久 别想\nepoch 200, perplexity 1.032214, time 0.42 sec\n - 分开 我不起跳广句语 我都娘子我爱你的模 语沉默 一壶好酒 再来一碗热粥 配上几斤的牛肉 我说店小二 三\n - 不分开 你说啊话你怎么打我手 你说啊 是不是你不想活 说你怎么面对我 甩开球我满腔的怒火 我想揍你已经很久\nepoch 250, perplexity 1.019992, time 0.42 sec\n - 分开 我不够翻译  我这样 那活  爱你 手过一阵莫名感动 我想带你 回我开外婆家 一起看着日落 一直到\n - 不分开 你喝水也能活 脑袋瓜有一点秀逗 猎物死了它比谁都难过 印地安斑鸠 会学人开口 仙人掌怕羞 蜥蝪横著\n","name":"stdout"}],"source":"rnn_layer = nn.RNN(input_size=vocab_size, hidden_size=num_hiddens)\nnum_steps, batch_size = 35, 2\nX = torch.rand(num_steps, batch_size, vocab_size)\nstate = None\nY, state_new = rnn_layer(X, state)\n\n#定义模型\nclass RNNModel(nn.Module):\n    def __init__(self, rnn_layer, vocab_size):\n        super(RNNModel, self).__init__()\n        self.rnn = rnn_layer\n        self.hidden_size = rnn_layer.hidden_size * (2 if rnn_layer.bidirectional else 1) \n        self.vocab_size = vocab_size\n        self.dense = nn.Linear(self.hidden_size, vocab_size)\n\n    def forward(self, inputs, state):\n        # inputs.shape: (batch_size, num_steps)\n        X = to_onehot(inputs, vocab_size)\n        X = torch.stack(X)  # X.shape: (num_steps, batch_size, vocab_size)\n        hiddens, state = self.rnn(X, state)\n        hiddens = hiddens.view(-1, hiddens.shape[-1])  # hiddens.shape: (num_steps * batch_size, hidden_size)\n        output = self.dense(hiddens)\n        return output, state\n        \n#实现一个预测函数，与前面的区别在于前向计算和初始化隐藏状态\ndef predict_rnn_pytorch(prefix, num_chars, model, vocab_size, device, idx_to_char,\n                      char_to_idx):\n    state = None\n    output = [char_to_idx[prefix[0]]]  # output记录prefix加上预测的num_chars个字符\n    for t in range(num_chars + len(prefix) - 1):\n        X = torch.tensor([output[-1]], device=device).view(1, 1)\n        (Y, state) = model(X, state)  # 前向计算不需要传入模型参数\n        if t < len(prefix) - 1:\n            output.append(char_to_idx[prefix[t + 1]])\n        else:\n            output.append(Y.argmax(dim=1).item())\n    return ''.join([idx_to_char[i] for i in output])\n\nmodel = RNNModel(rnn_layer, vocab_size).to(device)\n    \n#相邻采样\ndef train_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,\n                                corpus_indices, idx_to_char, char_to_idx,\n                                num_epochs, num_steps, lr, clipping_theta,\n                                batch_size, pred_period, pred_len, prefixes):\n    loss = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    model.to(device)\n    for epoch in range(num_epochs):\n        l_sum, n, start = 0.0, 0, time.time()\n        data_iter = d2l.data_iter_consecutive(corpus_indices, batch_size, num_steps, device) # 相邻采样\n        state = None\n        for X, Y in data_iter:\n            if state is not None:\n                # 使用detach函数从计算图分离隐藏状态\n                if isinstance (state, tuple): # LSTM, state:(h, c)  \n                    state[0].detach_()\n                    state[1].detach_()\n                else: \n                    state.detach_()\n            (output, state) = model(X, state) # output.shape: (num_steps * batch_size, vocab_size)\n            y = torch.flatten(Y.T)\n            l = loss(output, y.long())\n            \n            optimizer.zero_grad()\n            l.backward()\n            grad_clipping(model.parameters(), clipping_theta, device)\n            optimizer.step()\n            l_sum += l.item() * y.shape[0]\n            n += y.shape[0]\n        \n\n        if (epoch + 1) % pred_period == 0:\n            print('epoch %d, perplexity %f, time %.2f sec' % (\n                epoch + 1, math.exp(l_sum / n), time.time() - start))\n            for prefix in prefixes:\n                print(' -', predict_rnn_pytorch(\n                    prefix, pred_len, model, vocab_size, device, idx_to_char,\n                    char_to_idx))\n\nnum_epochs, batch_size, lr, clipping_theta = 250, 32, 1e-3, 1e-2\npred_period, pred_len, prefixes = 50, 50, ['分开', '不分开']\ntrain_and_predict_rnn_pytorch(model, num_hiddens, vocab_size, device,\n                            corpus_indices, idx_to_char, char_to_idx,\n                            num_epochs, num_steps, lr, clipping_theta,\n                            batch_size, pred_period, pred_len, prefixes)"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}